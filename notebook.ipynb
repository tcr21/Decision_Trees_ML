{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def read_dataset(filepath):\n",
    "    \"\"\"\n",
    "    Read .txt file from a specified filepath. (i.e. data/train_full.txt)\n",
    "    Returns 2 numpy arrays of the instances and the labels\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(filepath, dtype=str, delimiter=\",\")\n",
    "    instances = data[:,:-1]\n",
    "    instances = instances.astype(int)\n",
    "    labels = data[:,-1]\n",
    "\n",
    "    return instances, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_instances, train_full_labels = read_dataset(\"data/train_full.txt\")\n",
    "train_sub_instances, train_sub_labels = read_dataset(\"data/train_sub.txt\")\n",
    "train_noisy_instances, train_noisy_labels = read_dataset(\"data/train_noisy.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the datasets train full.txt, train sub.txt, and train noisy.txt (you can examine the raw text files directly or via Python). There are many questions you can ask yourself: \n",
    "\n",
    "How many samples/instances are there? Will that be enough to train a classifier? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Full Instances Shape:  (3900, 16)\n",
      "Train Noisy Instances Shape:  (3900, 16)\n",
      "Train Sub Instances Shape:  (600, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Full Instances Shape: \", train_full_instances.shape)\n",
    "print(\"Train Noisy Instances Shape: \", train_noisy_instances.shape)\n",
    "print(\"Train Sub Instances Shape: \", train_sub_instances.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique class labels (characters to be recognised) are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Full Labels:  ['A' 'C' 'E' 'G' 'O' 'Q']\n",
      "Train Full Label Count:  6\n",
      "Train Sub Labels:  ['A' 'C' 'E' 'G' 'O' 'Q']\n",
      "Train Sub Label Count:  6\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Full Labels: \",np.unique(train_full_labels))\n",
    "print(\"Train Full Label Count: \", len(np.unique(train_full_labels)))\n",
    "print(\"Train Sub Labels: \",np.unique(train_sub_labels))\n",
    "print(\"Train Sub Label Count: \", len(np.unique(train_sub_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " What is the distribution across the classes (e.g. 40% 'A's, 20% 'C's)? Are the samples balanced across all the classes, or are they biased towards one or two classes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Full Distribution\n",
      "A: 17.10%\n",
      "C: 15.36%\n",
      "E: 16.90%\n",
      "G: 17.21%\n",
      "O: 16.33%\n",
      "Q: 17.10%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Full Distribution\")\n",
    "labels, count = np.unique(train_full_labels, return_counts=True)\n",
    "for i in range(0, len(labels)):\n",
    "    print(f\"{labels[i]}: {(count[i]/(np.sum(count))*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sub Distribution\n",
      "A: 15.67%\n",
      "C: 31.17%\n",
      "E: 21.50%\n",
      "G: 3.50%\n",
      "O: 18.83%\n",
      "Q: 9.33%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Sub Distribution\")\n",
    "labels, count = np.unique(train_sub_labels, return_counts=True)\n",
    "for i in range(0, len(labels)):\n",
    "    print(f\"{labels[i]}: {(count[i]/(np.sum(count))*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does each of the 16 attributes represent?\n",
    "\n",
    "- 0: x-box (integer)\n",
    "\t- horizontal position of box\n",
    "- 1: y-box (integer)\n",
    "\t- vertical position of box\n",
    "- 2: width (integer)\n",
    "\t- width of box\n",
    "- 3: high (integer)\n",
    "\t- height of box\n",
    "- 4: onpix (integer)\n",
    "\t- total # on pixels\n",
    "- 5: x-bar (integer)\n",
    "\t- mean x of on pixels in box\n",
    "- 6: y-bar (integer)\n",
    "\t- mean y of on pixels in box\n",
    "- 7: x2bar (integer)\n",
    "\t- mean x variance\n",
    "- 8: y2bar (integer)\n",
    "\t- mean y variance\n",
    "- 9: xybar (integer)\n",
    "\t- mean x y correlation\n",
    "- 10: x2ybr (integer)\n",
    "\t- mean of x * x * y\n",
    "- 11: xy2br (integer)\n",
    "\t- mean of x * y * y\n",
    "- 12: x-ege (integer)\n",
    "\t- mean edge count left to right\n",
    "- 13: xegvy (integer)\n",
    "\t- correlation of x-ege with y\n",
    "- 14: y-ege (integer)\n",
    "\t- mean edge count bottom to top\n",
    "- 15: yegvx (integer)\n",
    "\t- correlation of y-ege with x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of attributes are provided in the dataset (Binary? Categorical/Discrete? Integers? Real numbers?) What are the ranges for each attribute in train full.txt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Full Min/Max\n",
      "x-box: Min = 2, Max = 10\n",
      "y-box: Min = 2, Max = 9\n",
      "width: Min = 0, Max = 10\n",
      "high: Min = 1, Max = 12\n",
      "onpix: Min = 1, Max = 8\n",
      "x-bar: Min = 1, Max = 9\n",
      "y-bar: Min = 5, Max = 11\n",
      "x2bar: Min = 2, Max = 10\n",
      "y2bar: Min = 2, Max = 10\n",
      "xybar: Min = 2, Max = 11\n",
      "x2ybr: Min = 1, Max = 8\n",
      "xy2br: Min = 0, Max = 14\n",
      "x-ege: Min = 2, Max = 12\n",
      "xegvy: Min = 2, Max = 13\n",
      "y-ege: Min = 3, Max = 14\n",
      "yegvx: Min = 0, Max = 12\n"
     ]
    }
   ],
   "source": [
    "labels_header=[\"x-box\", \"y-box\", \"width\", \"high\", \"onpix\", \"x-bar\", \"y-bar\", \"x2bar\", \"y2bar\", \"xybar\", \"x2ybr\" , \"xy2br\", \"x-ege\", \"xegvy\", \"y-ege\", \"yegvx\"]\n",
    "print(\"Train Full Min/Max\")\n",
    "for i in range(train_full_instances.shape[1]):\n",
    "    print(f\"{labels_header[i]}: Min = {min(train_full_instances[:][i])}, Max = {max(train_full_instances[:][i])}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_noisy.txt is actually a corrupted version of train_full.txt, where we have replaced the ground truth labels with the output of a simple automatic classifier. What proportion of labels in train_noisy.txt is different than from those in train_full.txt? (Note that the observations in both datasets are the same, although the ordering is different)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of different labels:  18.54%\n"
     ]
    }
   ],
   "source": [
    "# Create a new dtype so we can use intersect1d with 2D arrays\n",
    "nrows, ncols = train_full_instances.shape\n",
    "dtype={'names':['f{}'.format(i) for i in range(ncols)],\n",
    "       'formats':ncols * [train_full_instances.dtype]}\n",
    "\n",
    "intersect, indices_full, indices_noisy = np.intersect1d(train_full_instances.view(dtype), train_noisy_instances.view(dtype), return_indices=True)\n",
    "\n",
    "count_same_labels = np.count_nonzero(train_full_labels[indices_full] == train_noisy_labels[indices_noisy])\n",
    "print(f\"Proportion of different labels:  {((nrows-count_same_labels)/nrows)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has the class distribution been affected? Specify which classes have a substantially larger or smaller number of examples in train_noisy.txt compared to train_-full.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution\n",
      "A: Full = 17.10%, Noisy = 17.46%\n",
      "C: Full = 15.36%, Noisy = 14.64%\n",
      "E: Full = 16.90%, Noisy = 17.38%\n",
      "G: Full = 17.21%, Noisy = 15.95%\n",
      "O: Full = 16.33%, Noisy = 17.08%\n",
      "Q: Full = 17.10%, Noisy = 17.49%\n"
     ]
    }
   ],
   "source": [
    "labels, count_full = np.unique(train_full_labels, return_counts=True)\n",
    "labels, count_noisy = np.unique(train_noisy_labels, return_counts=True)\n",
    "print(\"Class Distribution\")\n",
    "for i in range(0, len(labels)):\n",
    "    print(f\"{labels[i]}: Full = {(count_full[i]/(np.sum(count_full))*100):.2f}%, Noisy = {(count_noisy[i]/(np.sum(count_noisy))*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Implement a tree data structure in Python - standard lib or np data structure for this?\n",
    "# 2) Implement find_best_node(dataset) function\n",
    "# 2.1) Find the split_point(dataset) for an attribute - start with binary?\n",
    "# 2.1.1) Sort the values of the attribute\n",
    "# 2.1.2) Store split point between two examples that have different class labels + the num of pos/neg examples each side (what is pos/neg here?)\n",
    "# 2.1.3) Select the most suitable split point based off the pos/neg examples\n",
    "# 2.2) Find information_gain(dataset[attr]) for an attribute\n",
    "# 2.2.1) Calc H(S_parent) - H'(S_children)\n",
    "# 2.3) Iterate across each attribute and store information gain + split\n",
    "# 3) Split dataset on attribute with largest information gain + split location\n",
    "# 4) Implement recursive induce_decision_tree function w/ above sub functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(data, labels):\n",
    "  H_total = 0\n",
    "  for label in np.unique(labels):\n",
    "      probability = len(data[labels==label]) / len(data)\n",
    "      H_total -= probability * np.log2(probability)\n",
    "  \n",
    "  return H_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information_gain(instances_col, labels):\n",
    "    \"\"\"Find the information gain for an attribute\n",
    "    Args:\n",
    "    instances_col (numpy.ndarray): Instances Column, numpy array of shape (N, )\n",
    "                       N is the number of instances\n",
    "    labels (numpy.ndarray): Class labels, numpy array of shape (N, )\n",
    "                       Each element in labels is a str\n",
    "    Returns:\n",
    "      best_attr_index: The index to the column that we want to split the data on\n",
    "      best_split_index: The index to to the split point in the column\n",
    "    \"\"\"\n",
    "    total_entropy = get_entropy(instances_col, labels)\n",
    "    max_info_gain = 0\n",
    "    split_index = 0\n",
    "    for index in range(1, len(instances_col)):\n",
    "        # Split on attribute where attr and class label change\n",
    "        if (\n",
    "            labels[index] != labels[index - 1]\n",
    "            and instances_col[index] != instances_col[index - 1]\n",
    "        ):\n",
    "            # Make the split\n",
    "            split_instances_left = instances_col[:index]\n",
    "            split_instances_right = instances_col[index:]\n",
    "            split_labels_left = labels[:index]\n",
    "            split_labels_right = labels[index:]\n",
    "            # Get the entropy of each data set\n",
    "            entropy_left = get_entropy(split_instances_left, split_labels_left)\n",
    "            entropy_right = get_entropy(split_instances_right, split_labels_right)\n",
    "            # Get the information gain\n",
    "            info_gain = (\n",
    "                total_entropy\n",
    "                - (len(split_instances_left) / len(instances_col)) * entropy_left\n",
    "                - (len(split_instances_right) / len(instances_col)) * entropy_right\n",
    "            )\n",
    "            # Check if this split leads to the highest information gain\n",
    "            if info_gain > max_info_gain:\n",
    "                max_info_gain = info_gain\n",
    "                split_index = index\n",
    "    return max_info_gain, split_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_node(instances, labels):\n",
    "    \"\"\"Find the best point to create a node in the decision tree\n",
    "    Args:\n",
    "    instances (numpy.ndarray): Instances, numpy array of shape (N, K)\n",
    "                       N is the number of instances\n",
    "                       K is the number of attributes\n",
    "    labels (numpy.ndarray): Class labels, numpy array of shape (N, )\n",
    "                       Each element in labels is a str\n",
    "    Returns:\n",
    "      best_attr_index: The index to the column that we want to split the data on\n",
    "      best_split_index: The index to to the split point in the column\n",
    "    \"\"\"\n",
    "    best_attr_index = 0\n",
    "    max_info_gain = 0\n",
    "    best_split_index = 0\n",
    "    for index in range(0, len(instances[0, :])):\n",
    "        indices = instances[:, index].argsort()  # returns sorted indices\n",
    "        sorted_instances = instances[indices]  # sort the instances based off sorted col\n",
    "        sorted_labels = labels[indices]  # sort the labels based off the sorted col\n",
    "        # Calculate the info gain and optimal split index for a given attribute\n",
    "        info_gain, split_index = get_information_gain( \n",
    "            sorted_instances[:, index], sorted_labels\n",
    "        )\n",
    "        if info_gain > max_info_gain:\n",
    "            max_info_gain = info_gain\n",
    "            best_attr_index = index\n",
    "            best_split_index = split_index\n",
    "\n",
    "    # Return the best attribute to split on, and the value at which we want to split\n",
    "    return best_attr_index, best_split_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset - change to take a node later\n",
    "def split_dataset(sorted_instances, sorted_labels, best_split):\n",
    "  split_instances_left = sorted_instances[:best_split, :]\n",
    "  split_instances_right = sorted_instances[best_split:, :]\n",
    "  split_labels_left = sorted_labels[:best_split]\n",
    "  split_labels_right = sorted_labels[best_split:]\n",
    "  return split_instances_left, split_instances_right, split_labels_left, split_labels_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leaf node, bottom of the tree, no more data split after this point\n",
    "class Leaf_Node:\n",
    "  def __init__(self, labels, depth):\n",
    "      self.label = max(set(labels), key=labels.tolist().count)\n",
    "      self.depth = depth\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f\"Node({self.depth}) [Label: {self.label}]\"\n",
    "\n",
    "  def predict(self, instance):\n",
    "    return self.label\n",
    "\n",
    "#Decision node, contains rule on how to split data, and reference to \n",
    "class Decision_Node:\n",
    "  def __init__(self, attribute, value, left, right, depth):\n",
    "      self.left = left\n",
    "      self.right = right\n",
    "      self.attribute = attribute\n",
    "      self.value = value\n",
    "      self.depth = depth\n",
    "\n",
    "  def __repr__(self):\n",
    "    tab = \"\\t\"\n",
    "    return f\"Node({self.depth}) [Attribute: {self.attribute} Value: {self.value}] \\\n",
    "      \\n {tab * self.depth} L -> {self.left} \\\n",
    "      \\n {tab * self.depth} R -> {self.right}\"\n",
    "\n",
    "  def predict(self, instance):\n",
    "    if instance[self.attribute] < self.value:\n",
    "      return self.left.predict(instance)\n",
    "    else:\n",
    "      return self.right.predict(instance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 23'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=19'>20</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m Decision_Node(best_attr, sorted_instances[best_split][best_attr], LeftNode, RightNode, depth)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=22'>23</a>\u001b[0m instances, labels \u001b[39m=\u001b[39m read_dataset(\u001b[39m\"\u001b[39m\u001b[39mdata/train_full.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=23'>24</a>\u001b[0m root \u001b[39m=\u001b[39m induce_decision_tree(instances, labels)\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 23'\u001b[0m in \u001b[0;36minduce_decision_tree\u001b[0;34m(instances, labels, depth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(labels)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(split_instances_left) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(split_instances_right) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=13'>14</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m Leaf_Node(labels, depth)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=15'>16</a>\u001b[0m LeftNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_left, split_labels_left, depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=16'>17</a>\u001b[0m RightNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_right, split_labels_right, depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=18'>19</a>\u001b[0m \u001b[39m# what to return if left node or right node does not exist\u001b[39;00m\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 23'\u001b[0m in \u001b[0;36minduce_decision_tree\u001b[0;34m(instances, labels, depth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(labels)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(split_instances_left) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(split_instances_right) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=13'>14</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m Leaf_Node(labels, depth)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=15'>16</a>\u001b[0m LeftNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_left, split_labels_left, depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=16'>17</a>\u001b[0m RightNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_right, split_labels_right, depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=18'>19</a>\u001b[0m \u001b[39m# what to return if left node or right node does not exist\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: induce_decision_tree at line 16 (2 times)]\u001b[0m\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 23'\u001b[0m in \u001b[0;36minduce_decision_tree\u001b[0;34m(instances, labels, depth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(labels)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(split_instances_left) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(split_instances_right) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=13'>14</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m Leaf_Node(labels, depth)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=15'>16</a>\u001b[0m LeftNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_left, split_labels_left, depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=16'>17</a>\u001b[0m RightNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_right, split_labels_right, depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=18'>19</a>\u001b[0m \u001b[39m# what to return if left node or right node does not exist\u001b[39;00m\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 23'\u001b[0m in \u001b[0;36minduce_decision_tree\u001b[0;34m(instances, labels, depth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=11'>12</a>\u001b[0m \u001b[39m#If we can no longer split data, return a leaf node\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(labels)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(split_instances_left) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(split_instances_right) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=13'>14</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m Leaf_Node(labels, depth)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=15'>16</a>\u001b[0m LeftNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_left, split_labels_left, depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=16'>17</a>\u001b[0m RightNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_right, split_labels_right, depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 22'\u001b[0m in \u001b[0;36mLeaf_Node.__init__\u001b[0;34m(self, labels, depth)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000021?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, labels, depth):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000021?line=3'>4</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mset\u001b[39m(labels), key\u001b[39m=\u001b[39mlabels\u001b[39m.\u001b[39;49mcount)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000021?line=4'>5</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdepth \u001b[39m=\u001b[39m depth\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'count'"
     ]
    }
   ],
   "source": [
    "      \n",
    "#From this function, return reference to root node\n",
    "def induce_decision_tree(instances, labels, depth=0):\n",
    "  #Split this data into tow, left and right\n",
    "  best_attr, best_split = find_best_node(instances, labels)\n",
    "\n",
    "  sorted_indices = instances[:, best_attr].argsort() # returns sorted indices\n",
    "  sorted_instances = instances[sorted_indices] # sort the instances based off sorted col\n",
    "  sorted_labels = labels[sorted_indices] # sort the labels based off the sorted col\n",
    "\n",
    "  split_instances_left, split_instances_right, split_labels_left, split_labels_right = split_dataset(sorted_instances, sorted_labels, best_split)\n",
    "\n",
    "  #If we can no longer split data, return a leaf node\n",
    "  if len(set(labels)) == 1 or len(split_instances_left) == 0 or len(split_instances_right) == 0:\n",
    "    return Leaf_Node(labels, depth)\n",
    "\n",
    "  LeftNode = induce_decision_tree(split_instances_left, split_labels_left, depth+1)\n",
    "  RightNode = induce_decision_tree(split_instances_right, split_labels_right, depth+1) \n",
    "\n",
    "  # what to return if left node or right node does not exist\n",
    "  return Decision_Node(best_attr, sorted_instances[best_split][best_attr], LeftNode, RightNode, depth)\n",
    "\n",
    "\n",
    "instances, labels = read_dataset(\"data/train_full.txt\")\n",
    "root = induce_decision_tree(instances, labels)\n",
    "\n",
    "#print(root)\n",
    "\n",
    "# print(root.predict([3,5,4,6,2,8,8,7,5,5,8,9,3,8,5,9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "177\n",
      "Node(0) [Attribute: 10 Value: 3]       \n",
      "  L -> Node(1) [Attribute: 15 Value: 13]       \n",
      " \t L -> Node(2) [Attribute: 15 Value: 10]       \n",
      " \t\t L -> Node(3) [Attribute: 0 Value: 6]       \n",
      " \t\t\t L -> Node(4) [Label: A]       \n",
      " \t\t\t R -> Node(4) [Attribute: 2 Value: 11]       \n",
      " \t\t\t\t L -> Node(5) [Label: G]       \n",
      " \t\t\t\t R -> Node(5) [Label: A]       \n",
      " \t\t R -> Node(3) [Attribute: 5 Value: 12]       \n",
      " \t\t\t L -> Node(4) [Label: G]       \n",
      " \t\t\t R -> Node(4) [Label: A]       \n",
      " \t R -> Node(2) [Label: Q]       \n",
      "  R -> Node(1) [Attribute: 5 Value: 7]       \n",
      " \t L -> Node(2) [Attribute: 14 Value: 5]       \n",
      " \t\t L -> Node(3) [Attribute: 11 Value: 11]       \n",
      " \t\t\t L -> Node(4) [Attribute: 7 Value: 5]       \n",
      " \t\t\t\t L -> Node(5) [Attribute: 8 Value: 7]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 3 Value: 6]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 5 Value: 6]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: C]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: E]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 6 Value: 7]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: C]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: A]       \n",
      " \t\t\t\t\t R -> Node(6) [Attribute: 14 Value: 3]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Label: C]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Label: E]       \n",
      " \t\t\t\t R -> Node(5) [Attribute: 9 Value: 11]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 11 Value: 9]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 9 Value: 7]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 7 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: O]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: O]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 12 Value: 4]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 7 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 8 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: C]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 2 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: G]       \n",
      " \t\t\t\t\t R -> Node(6) [Attribute: 14 Value: 4]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Label: C]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Label: E]       \n",
      " \t\t\t R -> Node(4) [Attribute: 6 Value: 7]       \n",
      " \t\t\t\t L -> Node(5) [Attribute: 8 Value: 9]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 7 Value: 5]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Label: C]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 9 Value: 13]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: G]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: C]       \n",
      " \t\t\t\t\t R -> Node(6) [Label: C]       \n",
      " \t\t\t\t R -> Node(5) [Attribute: 11 Value: 12]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 6 Value: 8]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 8 Value: 8]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 7 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 9 Value: 12]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 10 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: C]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: C]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 4 Value: 6]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: C]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: A]       \n",
      " \t\t\t\t\t R -> Node(6) [Attribute: 8 Value: 7]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 6 Value: 8]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 11 Value: 13]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 5 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: C]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: C]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Label: C]       \n",
      " \t\t R -> Node(3) [Attribute: 8 Value: 9]       \n",
      " \t\t\t L -> Node(4) [Attribute: 7 Value: 5]       \n",
      " \t\t\t\t L -> Node(5) [Attribute: 10 Value: 5]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 1 Value: 10]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Label: Q]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Label: O]       \n",
      " \t\t\t\t\t R -> Node(6) [Attribute: 8 Value: 6]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 11 Value: 11]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 13 Value: 11]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 6 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 0 Value: 4]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 1 Value: 12]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 15 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Attribute: 12 Value: 4]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: E]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 2 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 1 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: C]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 3 Value: 8]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: E]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 8 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 1 Value: 11]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: E]       \n",
      " \t\t\t\t R -> Node(5) [Attribute: 0 Value: 5]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 8 Value: 6]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 13 Value: 9]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: G]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 2 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: E]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 9 Value: 6]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: C]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: E]       \n",
      " \t\t\t\t\t R -> Node(6) [Attribute: 9 Value: 11]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 11 Value: 11]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 12 Value: 3]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 6 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 14 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 15 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 13 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Attribute: 7 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Attribute: 0 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 1 Value: 13]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 6 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Attribute: 3 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: C]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 6 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 5 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 0 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: C]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 6 Value: 7]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: G]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: C]       \n",
      " \t\t\t R -> Node(4) [Attribute: 15 Value: 10]       \n",
      " \t\t\t\t L -> Node(5) [Attribute: 13 Value: 11]       \n",
      " \t\t\t\t\t L -> Node(6) [Label: E]       \n",
      " \t\t\t\t\t R -> Node(6) [Label: C]       \n",
      " \t\t\t\t R -> Node(5) [Attribute: 1 Value: 9]       \n",
      " \t\t\t\t\t L -> Node(6) [Label: G]       \n",
      " \t\t\t\t\t R -> Node(6) [Label: C]       \n",
      " \t R -> Node(2) [Attribute: 14 Value: 4]       \n",
      " \t\t L -> Node(3) [Attribute: 11 Value: 9]       \n",
      " \t\t\t L -> Node(4) [Attribute: 9 Value: 7]       \n",
      " \t\t\t\t L -> Node(5) [Attribute: 10 Value: 6]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 6 Value: 6]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Label: Q]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 0 Value: 3]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: Q]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: O]       \n",
      " \t\t\t\t\t R -> Node(6) [Label: Q]       \n",
      " \t\t\t\t R -> Node(5) [Attribute: 12 Value: 4]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 7 Value: 6]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 3 Value: 3]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: O]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: Q]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Label: O]       \n",
      " \t\t\t\t\t R -> Node(6) [Attribute: 7 Value: 5]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Label: A]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Label: O]       \n",
      " \t\t\t R -> Node(4) [Attribute: 1 Value: 6]       \n",
      " \t\t\t\t L -> Node(5) [Attribute: 8 Value: 4]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 5 Value: 9]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Label: Q]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Label: A]       \n",
      " \t\t\t\t\t R -> Node(6) [Attribute: 5 Value: 8]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 6 Value: 8]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 0 Value: 2]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 0 Value: 3]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 0 Value: 4]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: G]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: C]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 9 Value: 7]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: Q]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: O]       \n",
      " \t\t\t\t R -> Node(5) [Attribute: 7 Value: 5]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 13 Value: 9]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Label: A]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 8 Value: 5]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: C]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: A]       \n",
      " \t\t\t\t\t R -> Node(6) [Attribute: 12 Value: 3]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Label: Q]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 12 Value: 4]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 9 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 1 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 8 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: O]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 13 Value: 10]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 0 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 1 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 4 Value: 4]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: A]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: G]       \n",
      " \t\t R -> Node(3) [Attribute: 7 Value: 4]       \n",
      " \t\t\t L -> Node(4) [Attribute: 8 Value: 5]       \n",
      " \t\t\t\t L -> Node(5) [Attribute: 14 Value: 8]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 11 Value: 7]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 0 Value: 7]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: A]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: G]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 10 Value: 4]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 1 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 1 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 5 Value: 12]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: A]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: Q]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 6 Value: 12]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Label: A]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: Q]       \n",
      " \t\t\t\t\t R -> Node(6) [Attribute: 2 Value: 4]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Label: E]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Label: G]       \n",
      " \t\t\t\t R -> Node(5) [Attribute: 5 Value: 11]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 10 Value: 8]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Label: E]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Label: A]       \n",
      " \t\t\t\t\t R -> Node(6) [Label: Q]       \n",
      " \t\t\t R -> Node(4) [Attribute: 12 Value: 3]       \n",
      " \t\t\t\t L -> Node(5) [Attribute: 8 Value: 7]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 8 Value: 4]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 11 Value: 9]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Label: A]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: Q]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 4 Value: 3]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 11 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 0 Value: 3]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 0 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 0 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 0 Value: 2]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Attribute: 9 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Attribute: 1 Value: 2]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: E]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 5 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 8 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 1 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: A]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 14 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 8 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: A]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: G]       \n",
      " \t\t\t\t\t R -> Node(6) [Attribute: 7 Value: 7]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 14 Value: 5]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 0 Value: 4]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: G]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 9 Value: 12]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 11 Value: 11]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 0 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: C]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 15 Value: 10]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 8 Value: 10]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 0 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 0 Value: 3]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: C]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Label: G]       \n",
      " \t\t\t\t R -> Node(5) [Attribute: 7 Value: 8]       \n",
      " \t\t\t\t\t L -> Node(6) [Attribute: 12 Value: 4]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 5 Value: 8]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 10 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 13 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 10 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 15 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Attribute: 6 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Attribute: 0 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Attribute: 0 Value: 4]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Attribute: 11 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 6 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Attribute: 11 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Attribute: 0 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Attribute: 14 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Attribute: 0 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Attribute: 1 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(15) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(15) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Attribute: 8 Value: 4]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 8 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 14 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: E]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 15 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Label: A]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 14 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 10 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 6 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Attribute: 13 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Attribute: 9 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Attribute: 2 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Attribute: 1 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Attribute: 0 Value: 4]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Attribute: 8 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 8 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 15 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Attribute: 10 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Attribute: 5 Value: 11]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Attribute: 1 Value: 10]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: Q]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 3 Value: 9]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 13 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 5 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 9 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 6 Value: 10]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Attribute: 0 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: A]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 10 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 14 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 8 Value: 1]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Attribute: 13 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Attribute: 7 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Attribute: 8 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(15) [Attribute: 9 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(16) [Attribute: 1 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(17) [Attribute: 2 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(18) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(18) [Attribute: 5 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(19) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(19) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(17) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(16) [Attribute: 12 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(17) [Attribute: 10 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(18) [Attribute: 13 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(19) [Attribute: 0 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(20) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(20) [Attribute: 1 Value: 12]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(21) [Attribute: 11 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(22) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(22) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(21) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(19) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(18) [Attribute: 0 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(19) [Attribute: 2 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(20) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(20) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(19) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(17) [Attribute: 8 Value: 2]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(18) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(18) [Attribute: 5 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(19) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(19) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(15) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Attribute: 11 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Attribute: 1 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(15) [Attribute: 4 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(16) [Attribute: 0 Value: 4]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(17) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(17) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(16) [Attribute: 3 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(17) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(17) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(15) [Attribute: 13 Value: 11]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(16) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(16) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Attribute: 15 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(15) [Attribute: 7 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(16) [Attribute: 0 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(17) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(17) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(16) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(15) [Attribute: 5 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(16) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(16) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Attribute: 15 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: A]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Attribute: 9 Value: 10]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Attribute: 12 Value: 11]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Attribute: 7 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(15) [Attribute: 15 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(16) [Attribute: 10 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(17) [Attribute: 1 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(18) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(18) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(17) [Attribute: 12 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(18) [Attribute: 15 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(19) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(19) [Attribute: 9 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(20) [Attribute: 11 Value: 10]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(21) [Attribute: 10 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(22) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(22) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(21) [Attribute: 5 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(22) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(22) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(20) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(18) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(16) [Attribute: 15 Value: 13]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(17) [Attribute: 4 Value: 10]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(18) [Attribute: 12 Value: 10]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(19) [Attribute: 8 Value: 3]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(20) [Attribute: 0 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(21) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(21) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(20) [Attribute: 13 Value: 11]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(21) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(21) [Attribute: 0 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(22) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(22) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(19) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(18) [Attribute: 1 Value: 10]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(19) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(19) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(17) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(15) [Attribute: 5 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(16) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(16) [Attribute: 9 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(17) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(17) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Attribute: 1 Value: 10]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(15) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(15) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Attribute: 1 Value: 10]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 11 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 5 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: A]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Attribute: 1 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Attribute: 4 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Label: E]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 1 Value: 10]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 0 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 0 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: E]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: Q]       \n",
      " \t\t\t\t\t R -> Node(6) [Attribute: 9 Value: 7]       \n",
      " \t\t\t\t\t\t L -> Node(7) [Attribute: 5 Value: 8]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 6 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 10 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 9 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 8 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 11 Value: 11]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 4 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: A]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 12 Value: 4]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 8 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: C]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 14 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 10 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 11 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Attribute: 1 Value: 4]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Attribute: 11 Value: 11]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 3 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 15 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: A]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 11 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: Q]       \n",
      " \t\t\t\t\t\t R -> Node(7) [Attribute: 14 Value: 8]       \n",
      " \t\t\t\t\t\t\t L -> Node(8) [Attribute: 11 Value: 11]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Attribute: 4 Value: 3]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Attribute: 10 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Attribute: 0 Value: 5]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Attribute: 5 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Attribute: 5 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t L -> Node(12) [Attribute: 2 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Attribute: 8 Value: 7]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t L -> Node(14) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t\t R -> Node(14) [Label: C]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t R -> Node(12) [Attribute: 1 Value: 9]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t L -> Node(13) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t\t\t\t\t R -> Node(13) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Attribute: 0 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t L -> Node(10) [Attribute: 2 Value: 6]       \n",
      " \t\t\t\t\t\t\t\t\t\t L -> Node(11) [Label: G]       \n",
      " \t\t\t\t\t\t\t\t\t\t R -> Node(11) [Label: O]       \n",
      " \t\t\t\t\t\t\t\t\t R -> Node(10) [Label: C]       \n",
      " \t\t\t\t\t\t\t R -> Node(8) [Attribute: 11 Value: 8]       \n",
      " \t\t\t\t\t\t\t\t L -> Node(9) [Label: Q]       \n",
      " \t\t\t\t\t\t\t\t R -> Node(9) [Label: A]\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w5/srtbhlhs71jcqz1khzsh_n3w0000gn/T/ipykernel_42454/3547450893.py:2: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predictions = np.zeros((x_test.shape[0],), dtype=np.object)\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = read_dataset(\"data/test.txt\")\n",
    "predictions = np.zeros((x_test.shape[0],), dtype=np.object)\n",
    "for i, instance in enumerate(x_test):\n",
    "  predictions[i] = root.predict(instance)\n",
    "print(predictions.shape)\n",
    "print(np.count_nonzero(predictions == y_test))\n",
    "print(root)\n",
    "\n",
    "def dfs(node):\n",
    "  if node is None:\n",
    "    return 0\n",
    "  \n",
    "  if isinstance(node, Leaf_Node):\n",
    "    return node.depth\n",
    "\n",
    "  return max(node.depth, dfs(node.left), dfs(node.right))\n",
    "\n",
    "print(dfs(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0  0  1  1]\n",
      " [ 0 34  2  1  0  0]\n",
      " [ 0  1 25  0  0  0]\n",
      " [ 0  0  0 26  1  0]\n",
      " [ 0  2  0  0 26  6]\n",
      " [ 0  0  0  0  2 40]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w5/srtbhlhs71jcqz1khzsh_n3w0000gn/T/ipykernel_42454/3933096852.py:20: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  confusion = np.zeros((len(class_labels), len(class_labels)), dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "def confusion_matrix(y_gold, y_prediction, class_labels=None):\n",
    "    \"\"\" Compute the confusion matrix.\n",
    "        \n",
    "    Args:\n",
    "        y_gold (np.ndarray): the correct ground truth/gold standard labels\n",
    "        y_prediction (np.ndarray): the predicted labels\n",
    "        class_labels (np.ndarray): a list of unique class labels. \n",
    "                               Defaults to the union of y_gold and y_prediction.\n",
    "\n",
    "    Returns:\n",
    "        np.array : shape (C, C), where C is the number of classes. \n",
    "                   Rows are ground truth per class, columns are predictions\n",
    "    \"\"\"\n",
    "\n",
    "    # if no class_labels are given, we obtain the set of unique class labels from\n",
    "    # the union of the ground truth annotation and the prediction\n",
    "    if not class_labels:\n",
    "        class_labels = np.unique(np.concatenate((y_gold, y_prediction)))\n",
    "\n",
    "    confusion = np.zeros((len(class_labels), len(class_labels)), dtype=np.int)\n",
    "\n",
    "    # for each correct class (row), \n",
    "    # compute how many instances are predicted for each class (columns)\n",
    "    for (i, label) in enumerate(class_labels):\n",
    "        # get predictions where the ground truth is the current class label\n",
    "        indices = (y_gold == label)\n",
    "        gold = y_gold[indices]\n",
    "        predictions = y_prediction[indices]\n",
    "\n",
    "        # quick way to get the counts per label\n",
    "        (unique_labels, counts) = np.unique(predictions, return_counts=True)\n",
    "\n",
    "        # convert the counts to a dictionary\n",
    "        frequency_dict = dict(zip(unique_labels, counts))\n",
    "\n",
    "        # fill up the confusion matrix for the current row\n",
    "        for (j, class_label) in enumerate(class_labels):\n",
    "            confusion[i, j] = frequency_dict.get(class_label, 0)\n",
    "\n",
    "    return confusion\n",
    "\n",
    "confusion = confusion_matrix(y_test, predictions)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_gold, y_prediction):\n",
    "    \"\"\" Compute the accuracy given the ground truth and predictions\n",
    "\n",
    "    Args:\n",
    "        y_gold (np.ndarray): the correct ground truth/gold standard labels\n",
    "        y_prediction (np.ndarray): the predicted labels\n",
    "\n",
    "    Returns:\n",
    "        float : the accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(y_gold) == len(y_prediction)  \n",
    "    \n",
    "    try:\n",
    "        return np.sum(y_gold == y_prediction) / len(y_gold)\n",
    "    except ZeroDivisionError:\n",
    "        return 0.\n",
    "\n",
    "# Compute accuracy on predictions for RandomClassifier and KNNClassifier from earlier\n",
    "print(accuracy(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_gold, y_prediction):\n",
    "    \"\"\" Compute the precision score per class given the ground truth and predictions\n",
    "        \n",
    "    Also return the macro-averaged precision across classes.\n",
    "        \n",
    "    Args:\n",
    "        y_gold (np.ndarray): the correct ground truth/gold standard labels\n",
    "        y_prediction (np.ndarray): the predicted labels\n",
    "\n",
    "    Returns:\n",
    "        tuple: returns a tuple (precisions, macro_precision) where\n",
    "            - precisions is a np.ndarray of shape (C,), where each element is the \n",
    "              precision for class c\n",
    "            - macro-precision is macro-averaged precision (a float) \n",
    "    \"\"\"\n",
    "\n",
    "    confusion = confusion_matrix(y_gold, y_prediction)\n",
    "    p = np.zeros((len(confusion), ))\n",
    "    for c in range(confusion.shape[0]):\n",
    "        if np.sum(confusion[:, c]) > 0:\n",
    "            p[c] = confusion[c, c] / np.sum(confusion[:, c])\n",
    "\n",
    "    ## Alternative solution without computing the confusion matrix\n",
    "    #class_labels = np.unique(np.concatenate((y_gold, y_prediction)))\n",
    "    #p = np.zeros((len(class_labels), ))\n",
    "    #for (c, label) in enumerate(class_labels):\n",
    "    #    indices = (y_prediction == label) # get instances predicted as label\n",
    "    #    correct = np.sum(y_gold[indices] == y_prediction[indices]) # intersection\n",
    "    #    if np.sum(indices) > 0:\n",
    "    #        p[c] = correct / np.sum(indices)     \n",
    "\n",
    "    # Compute the macro-averaged precision\n",
    "    macro_p = 0.\n",
    "    if len(p) > 0:\n",
    "        macro_p = np.mean(p)\n",
    "    \n",
    "    return (p, macro_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.91891892 0.92592593 0.96296296 0.86666667 0.85106383]\n",
      "0.9209230507102847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w5/srtbhlhs71jcqz1khzsh_n3w0000gn/T/ipykernel_42454/3933096852.py:20: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  confusion = np.zeros((len(class_labels), len(class_labels)), dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "(p, macro_p) = precision(y_test, predictions)\n",
    "print(p)\n",
    "print(macro_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_gold, y_prediction):\n",
    "    \"\"\" Compute the recall score per class given the ground truth and predictions\n",
    "        \n",
    "    Also return the macro-averaged recall across classes.\n",
    "        \n",
    "    Args:\n",
    "        y_gold (np.ndarray): the correct ground truth/gold standard labels\n",
    "        y_prediction (np.ndarray): the predicted labels\n",
    "\n",
    "    Returns:\n",
    "        tuple: returns a tuple (recalls, macro_recall) where\n",
    "            - recalls is a np.ndarray of shape (C,), where each element is the \n",
    "                recall for class c\n",
    "            - macro-recall is macro-averaged recall (a float) \n",
    "    \"\"\"\n",
    "\n",
    "    confusion = confusion_matrix(y_gold, y_prediction)\n",
    "    r = np.zeros((len(confusion), ))\n",
    "    for c in range(confusion.shape[0]):\n",
    "        if np.sum(confusion[c, :]) > 0:\n",
    "            r[c] = confusion[c, c] / np.sum(confusion[c, :])\n",
    "\n",
    "    ## Alternative solution without computing the confusion matrix\n",
    "    #class_labels = np.unique(np.concatenate((y_gold, y_prediction)))\n",
    "    #r = np.zeros((len(class_labels), ))\n",
    "    #for (c, label) in enumerate(class_labels):\n",
    "    #    indices = (y_gold == label) # get instances for current label\n",
    "    #    correct = np.sum(y_gold[indices] == y_prediction[indices]) # intersection\n",
    "    #    if np.sum(indices) > 0:\n",
    "    #        r[c] = correct / np.sum(indices)     \n",
    "\n",
    "    # Compute the macro-averaged recall\n",
    "    macro_r = 0.\n",
    "    if len(r) > 0:\n",
    "        macro_r = np.mean(r)\n",
    "    \n",
    "    return (r, macro_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w5/srtbhlhs71jcqz1khzsh_n3w0000gn/T/ipykernel_42454/3933096852.py:20: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  confusion = np.zeros((len(class_labels), len(class_labels)), dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94117647 0.91891892 0.96153846 0.96296296 0.76470588 0.95238095]\n",
      "0.9169472747904122\n"
     ]
    }
   ],
   "source": [
    "(r, macro_r) = recall(y_test, predictions)\n",
    "print(r)\n",
    "print(macro_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_gold, y_prediction):\n",
    "    \"\"\" Compute the F1-score per class given the ground truth and predictions\n",
    "        \n",
    "    Also return the macro-averaged F1-score across classes.\n",
    "        \n",
    "    Args:\n",
    "        y_gold (np.ndarray): the correct ground truth/gold standard labels\n",
    "        y_prediction (np.ndarray): the predicted labels\n",
    "\n",
    "    Returns:\n",
    "        tuple: returns a tuple (f1s, macro_f1) where\n",
    "            - f1s is a np.ndarray of shape (C,), where each element is the \n",
    "              f1-score for class c\n",
    "            - macro-f1 is macro-averaged f1-score (a float) \n",
    "    \"\"\"\n",
    "\n",
    "    (precisions, macro_p) = precision(y_gold, y_prediction)\n",
    "    (recalls, macro_r) = recall(y_gold, y_prediction)\n",
    "\n",
    "    # just to make sure they are of the same length\n",
    "    assert len(precisions) == len(recalls)\n",
    "\n",
    "    f = np.zeros((len(precisions), ))\n",
    "    for c, (p, r) in enumerate(zip(precisions, recalls)):\n",
    "        if p + r > 0:\n",
    "            f[c] = 2 * p * r / (p + r)\n",
    "\n",
    "    # Compute the macro-averaged F1\n",
    "    macro_f = 0.\n",
    "    if len(f) > 0:\n",
    "        macro_f = np.mean(f)\n",
    "    \n",
    "    return (f, macro_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96969697 0.91891892 0.94339623 0.96296296 0.8125     0.8988764 ]\n",
      "0.9177252470813878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w5/srtbhlhs71jcqz1khzsh_n3w0000gn/T/ipykernel_42454/3933096852.py:20: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  confusion = np.zeros((len(class_labels), len(class_labels)), dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "(f1, macro_f1) = f1_score(y_test, predictions)\n",
    "print(f1)\n",
    "print(macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "def k_fold_split(n_splits, n_instances, random_generator=default_rng()):\n",
    "    \"\"\" Split n_instances into n mutually exclusive splits at random.\n",
    "    \n",
    "    Args:\n",
    "        n_splits (int): Number of splits\n",
    "        n_instances (int): Number of instances to split\n",
    "        random_generator (np.random.Generator): A random generator\n",
    "\n",
    "    Returns:\n",
    "        list: a list (length n_splits). Each element in the list should contain a \n",
    "            numpy array giving the indices of the instances in that split.\n",
    "    \"\"\"\n",
    "\n",
    "    # generate a random permutation of indices from 0 to n_instances\n",
    "    shuffled_indices = random_generator.permutation(n_instances)\n",
    "\n",
    "    # split shuffled indices into almost equal sized splits\n",
    "    split_indices = np.array_split(shuffled_indices, n_splits)\n",
    "\n",
    "    return split_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_k_fold(n_folds, n_instances, random_generator=default_rng()):\n",
    "    \"\"\" Generate train and test indices at each fold.\n",
    "    \n",
    "    Args:\n",
    "        n_folds (int): Number of folds\n",
    "        n_instances (int): Total number of instances\n",
    "        random_generator (np.random.Generator): A random generator\n",
    "\n",
    "    Returns:\n",
    "        list: a list of length n_folds. Each element in the list is a list (or tuple) \n",
    "            with two elements: a numpy array containing the train indices, and another \n",
    "            numpy array containing the test indices.\n",
    "    \"\"\"\n",
    "\n",
    "    # split the dataset into k splits\n",
    "    split_indices = k_fold_split(n_folds, n_instances, random_generator)\n",
    "\n",
    "    folds = []\n",
    "    for k in range(n_folds):\n",
    "        # pick k as test\n",
    "        test_indices = split_indices[k]\n",
    "\n",
    "        # combine remaining splits as train\n",
    "        # this solution is fancy and worked for me\n",
    "        # feel free to use a more verbose solution that's more readable\n",
    "        train_indices = np.hstack(split_indices[:k] + split_indices[k+1:])\n",
    "\n",
    "        folds.append([train_indices, test_indices])\n",
    "\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w5/srtbhlhs71jcqz1khzsh_n3w0000gn/T/ipykernel_42454/2173650932.py:12: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predictions = np.zeros((test_indices.shape[0],), dtype=np.object)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93846154 0.90512821 0.92051282 0.93589744 0.93589744 0.92820513\n",
      " 0.90769231 0.92051282 0.92051282 0.87948718]\n",
      "0.9192307692307693\n",
      "0.01709508543670081\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For quick testing\n",
    "seed = 60012\n",
    "rg = default_rng(seed)\n",
    "n_folds = 10\n",
    "accuracies = np.zeros((n_folds, ))\n",
    "for i, (train_indices, test_indices) in enumerate(train_test_k_fold(n_folds, len(instances), rg)):\n",
    "    # get the dataset from the correct splits\n",
    "    x_train = instances[train_indices, :]\n",
    "    y_train = labels[train_indices]\n",
    "    x_test = instances[test_indices, :]\n",
    "    y_test = labels[test_indices]\n",
    "    predictions = np.zeros((test_indices.shape[0],), dtype=np.object)\n",
    "    root = induce_decision_tree(x_train, y_train)\n",
    "    for j, instance in enumerate(x_test):\n",
    "        predictions[j] = root.predict(instance)   \n",
    "    acc = accuracy(y_test, predictions)\n",
    "    accuracies[i] = acc\n",
    "print(accuracies)\n",
    "print(accuracies.mean())\n",
    "print(accuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from numpy.random import default_rng\n",
    "\n",
    "def induce_random_decision_tree(instances, labels, attributes_per_tree, depth=0):\n",
    "  #Get a shuffled array of the indexes of the attributes\n",
    "  random_indexes = default_rng().permutation(len(instances[0, :]))\n",
    "  #Take the first attributes_per_tree indexes\n",
    "  random_indexes_in_each_tree = random_indexes[:attributes_per_tree]\n",
    "\n",
    "  #Create a new np array with only the attributes we want\n",
    "  new_instances = instances[:, random_indexes_in_each_tree]\n",
    "\n",
    "  #Find the best split points for the two \n",
    "  best_attr, best_split = find_best_node(new_instances, labels)\n",
    "\n",
    "  sorted_indices = instances[:, best_attr].argsort() # returns sorted indices\n",
    "  sorted_instances = instances[sorted_indices] # sort the instances based off sorted col\n",
    "  sorted_labels = labels[sorted_indices] # sort the labels based off the sorted col\n",
    "\n",
    "\n",
    "  #Split the total dataset based on the best split point\n",
    "  split_instances_left, split_instances_right, split_labels_left, split_labels_right = split_dataset(sorted_instances, sorted_labels, best_split)\n",
    "\n",
    "  #If we can no longer split data, return a leaf node\n",
    "  if len(set(labels)) == 1 or len(split_instances_left) == 0 or len(split_instances_right) == 0:\n",
    "    return Leaf_Node(labels, depth)\n",
    "\n",
    "  LeftNode = induce_random_decision_tree(split_instances_left, split_labels_left, attributes_per_tree, depth+1)\n",
    "  RightNode = induce_random_decision_tree(split_instances_right, split_labels_right, attributes_per_tree, depth+1) \n",
    "\n",
    "  #Remap the best attribute its original index\n",
    "  best_attr = random_indexes_in_each_tree[best_attr]\n",
    "\n",
    "  # what to return if left node or right node does not exist\n",
    "  return Decision_Node(best_attr, sorted_instances[best_split][best_attr], LeftNode, RightNode, depth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #Read in data\n",
    "# val_instances, val_labels = read_dataset(\"data/validation.txt\")\n",
    "\n",
    "# number_of_trees = 70\n",
    "# #max_depth = 14\n",
    "# decision_trees = []\n",
    "\n",
    "# accuracies = []\n",
    "# for depth in range(0, 22):\n",
    "#     for i in range(0, number_of_trees):\n",
    "#         #Create a new random combination of the row indexes from new_instances\n",
    "#         random_row_indexes = default_rng().choice(len(train_instances), len(train_instances))\n",
    "#         new_instances = train_instances[random_row_indexes, :]\n",
    "#         new_labels = train_labels[random_row_indexes]\n",
    "\n",
    "#         #Now we have the new instances and labels, we can create a new decision tree\n",
    "#         new_decision_tree = induce_random_decision_tree(new_instances, new_labels, depth)\n",
    "#         decision_trees.append(new_decision_tree)\n",
    "\n",
    "\n",
    "#     predictions = []\n",
    "#     for i in val_instances:\n",
    "#         votes = []\n",
    "#         for j in range(len(decision_trees)):\n",
    "#             votes.append(decision_trees[j].predict(i))\n",
    "        \n",
    "#         most_voted_label = max(set(votes), key=votes.count)\n",
    "#         predictions.append(most_voted_label)\n",
    "\n",
    "#     accuracies.append(accuracy(val_labels, predictions))\n",
    "\n",
    "    \n",
    "#print(accuracy(val_labels, predictions))\n",
    "\n",
    "# confusion = confusion_matrix(test_labels, np.array(predictions))\n",
    "# print(confusion)\n",
    "\n",
    "# (p, macro_p) = precision(test_labels, np.array(predictions))\n",
    "# print(\"precison:\", p)\n",
    "# print(\"macro prec:\", macro_p)\n",
    "# (r, macro_r) = recall(test_labels, np.array(predictions))\n",
    "# print(\"recall\", r)\n",
    "# print(\"macro recall:\", macro_r)\n",
    "# (f1, macro_f1) = f1_score(test_labels, np.array(predictions))\n",
    "# print(\"f1:\", f1)\n",
    "# print(\"macro f1:\", macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 39'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000042?line=20'>21</a>\u001b[0m     new_labels \u001b[39m=\u001b[39m train_labels[random_row_indexes]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000042?line=22'>23</a>\u001b[0m     \u001b[39m#Now we have the new instances and labels, we can create a new decision tree\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000042?line=23'>24</a>\u001b[0m     new_decision_tree \u001b[39m=\u001b[39m induce_random_decision_tree(new_instances, new_labels, attributes_per_tree, depth)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000042?line=24'>25</a>\u001b[0m     decision_trees\u001b[39m.\u001b[39mappend(new_decision_tree)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000042?line=27'>28</a>\u001b[0m predictions \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 36'\u001b[0m in \u001b[0;36minduce_random_decision_tree\u001b[0;34m(instances, labels, max_depth, depth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000035?line=38'>39</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m Leaf_Node(labels, depth)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000035?line=40'>41</a>\u001b[0m LeftNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_left, split_labels_left, depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000035?line=41'>42</a>\u001b[0m RightNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_right, split_labels_right, depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000035?line=43'>44</a>\u001b[0m \u001b[39m#Remap the best attribute its original index\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000035?line=44'>45</a>\u001b[0m best_attr \u001b[39m=\u001b[39m random_indexes_in_each_tree[best_attr]\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 23'\u001b[0m in \u001b[0;36minduce_decision_tree\u001b[0;34m(instances, labels, depth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=13'>14</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m Leaf_Node(labels, depth)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=15'>16</a>\u001b[0m LeftNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_left, split_labels_left, depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=16'>17</a>\u001b[0m RightNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_right, split_labels_right, depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=18'>19</a>\u001b[0m \u001b[39m# what to return if left node or right node does not exist\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=19'>20</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Decision_Node(best_attr, sorted_instances[best_split][best_attr], LeftNode, RightNode, depth)\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 23'\u001b[0m in \u001b[0;36minduce_decision_tree\u001b[0;34m(instances, labels, depth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=13'>14</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m Leaf_Node(labels, depth)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=15'>16</a>\u001b[0m LeftNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_left, split_labels_left, depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=16'>17</a>\u001b[0m RightNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_right, split_labels_right, depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=18'>19</a>\u001b[0m \u001b[39m# what to return if left node or right node does not exist\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=19'>20</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Decision_Node(best_attr, sorted_instances[best_split][best_attr], LeftNode, RightNode, depth)\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 23'\u001b[0m in \u001b[0;36minduce_decision_tree\u001b[0;34m(instances, labels, depth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=13'>14</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m Leaf_Node(labels, depth)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=15'>16</a>\u001b[0m LeftNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_left, split_labels_left, depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=16'>17</a>\u001b[0m RightNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_right, split_labels_right, depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=18'>19</a>\u001b[0m \u001b[39m# what to return if left node or right node does not exist\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=19'>20</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Decision_Node(best_attr, sorted_instances[best_split][best_attr], LeftNode, RightNode, depth)\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 23'\u001b[0m in \u001b[0;36minduce_decision_tree\u001b[0;34m(instances, labels, depth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(labels)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(split_instances_left) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(split_instances_right) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=13'>14</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m Leaf_Node(labels, depth)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=15'>16</a>\u001b[0m LeftNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_left, split_labels_left, depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=16'>17</a>\u001b[0m RightNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_right, split_labels_right, depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=18'>19</a>\u001b[0m \u001b[39m# what to return if left node or right node does not exist\u001b[39;00m\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 23'\u001b[0m in \u001b[0;36minduce_decision_tree\u001b[0;34m(instances, labels, depth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(labels)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(split_instances_left) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(split_instances_right) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=13'>14</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m Leaf_Node(labels, depth)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=15'>16</a>\u001b[0m LeftNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_left, split_labels_left, depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=16'>17</a>\u001b[0m RightNode \u001b[39m=\u001b[39m induce_decision_tree(split_instances_right, split_labels_right, depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=18'>19</a>\u001b[0m \u001b[39m# what to return if left node or right node does not exist\u001b[39;00m\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 23'\u001b[0m in \u001b[0;36minduce_decision_tree\u001b[0;34m(instances, labels, depth)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minduce_decision_tree\u001b[39m(instances, labels, depth\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=2'>3</a>\u001b[0m   \u001b[39m#Split this data into tow, left and right\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=3'>4</a>\u001b[0m   best_attr, best_split \u001b[39m=\u001b[39m find_best_node(instances, labels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=5'>6</a>\u001b[0m   sorted_indices \u001b[39m=\u001b[39m instances[:, best_attr]\u001b[39m.\u001b[39margsort() \u001b[39m# returns sorted indices\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000022?line=6'>7</a>\u001b[0m   sorted_instances \u001b[39m=\u001b[39m instances[sorted_indices] \u001b[39m# sort the instances based off sorted col\u001b[39;00m\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 20'\u001b[0m in \u001b[0;36mfind_best_node\u001b[0;34m(instances, labels)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=18'>19</a>\u001b[0m sorted_labels \u001b[39m=\u001b[39m labels[indices]  \u001b[39m# sort the labels based off the sorted col\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=19'>20</a>\u001b[0m \u001b[39m# Calculate the info gain and optimal split index for a given attribute\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=20'>21</a>\u001b[0m info_gain, split_index \u001b[39m=\u001b[39m get_information_gain( \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=21'>22</a>\u001b[0m     sorted_instances[:, index], sorted_labels\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=22'>23</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m info_gain \u001b[39m>\u001b[39m max_info_gain:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=24'>25</a>\u001b[0m     max_info_gain \u001b[39m=\u001b[39m info_gain\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 19'\u001b[0m in \u001b[0;36mget_information_gain\u001b[0;34m(instances_col, labels)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=24'>25</a>\u001b[0m split_labels_right \u001b[39m=\u001b[39m labels[index:]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=25'>26</a>\u001b[0m \u001b[39m# Get the entropy of each data set\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=26'>27</a>\u001b[0m entropy_left \u001b[39m=\u001b[39m get_entropy(split_instances_left, split_labels_left)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=27'>28</a>\u001b[0m entropy_right \u001b[39m=\u001b[39m get_entropy(split_instances_right, split_labels_right)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=28'>29</a>\u001b[0m \u001b[39m# Get the information gain\u001b[39;00m\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 18'\u001b[0m in \u001b[0;36mget_entropy\u001b[0;34m(data, labels)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000017?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39munique(labels):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000017?line=3'>4</a>\u001b[0m     probability \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data[labels\u001b[39m==\u001b[39mlabel]) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000017?line=4'>5</a>\u001b[0m     H_total \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m probability \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49mlog2(probability)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000017?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m H_total\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#This box is for evaluating number of trees\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#Read in data\n",
    "train_instances, train_labels = read_dataset(\"data/train_full.txt\")\n",
    "val_instances, val_labels = read_dataset(\"data/validation.txt\")\n",
    "#Get number of attributes in the dataset\n",
    "num_attributes = len(train_instances[0, :])\n",
    "#Take the square root of number of attributes and round up (optimal number of attibutes per tree?)\n",
    "attributes_per_tree = math.ceil(np.sqrt(num_attributes)) +1\n",
    "\n",
    "accuracies = []\n",
    "max_depth = 22\n",
    "for number_of_trees in range(30, 400, 30):\n",
    "    decision_trees = []\n",
    "    for i in range(0, number_of_trees):\n",
    "        #Create a new random combination of the row indexes from new_instances\n",
    "        random_row_indexes = default_rng().choice(len(train_instances), len(train_instances))\n",
    "        new_instances = train_instances[random_row_indexes, :]\n",
    "        new_labels = train_labels[random_row_indexes]\n",
    "\n",
    "        #Now we have the new instances and labels, we can create a new decision tree\n",
    "        new_decision_tree = induce_random_decision_tree(new_instances, new_labels, attributes_per_tree, max_depth)\n",
    "        decision_trees.append(new_decision_tree)\n",
    "\n",
    "\n",
    "    predictions = []\n",
    "    for i in val_instances:\n",
    "        votes = []\n",
    "        for j in range(len(decision_trees)):\n",
    "            votes.append(decision_trees[j].predict(i))\n",
    "        \n",
    "        most_voted_label = max(set(votes), key=votes.count)\n",
    "        predictions.append(most_voted_label)\n",
    "\n",
    "    accuracies.append(accuracy(val_labels, predictions))\n",
    "\n",
    "\n",
    "n = [30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330, 360, 390]\n",
    "\n",
    "plt.plot(n, accuracies)\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data for pruning with 1 tree\n",
    "accuracies = [0.14, 0.28, 0.47, 0.64, 0.72, 0.76, 0.8, 0.85, 0.88, 0.9, 0.9, 0.91, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.92, 0.92, 0.92, 0.92]\n",
    "n = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
    "plt.figure()\n",
    "plt.plot(n, accuracies)\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 40'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=86'>87</a>\u001b[0m     new_labels \u001b[39m=\u001b[39m x_train[random_row_indexes]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=88'>89</a>\u001b[0m     \u001b[39m# Now we have the new instances and labels, we can create a new decision tree\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=89'>90</a>\u001b[0m     new_decision_tree \u001b[39m=\u001b[39m induce_random_decision_tree(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=90'>91</a>\u001b[0m         new_instances, new_labels, attributes_per_tree\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=91'>92</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=92'>93</a>\u001b[0m     decision_trees\u001b[39m.\u001b[39mappend(new_decision_tree)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=95'>96</a>\u001b[0m predictions1 \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 40'\u001b[0m in \u001b[0;36minduce_random_decision_tree\u001b[0;34m(instances, labels, num_attributes_per_tree, depth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=19'>20</a>\u001b[0m new_instances \u001b[39m=\u001b[39m instances[:, random_indexes_in_each_tree]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=21'>22</a>\u001b[0m \u001b[39m# Find the best split point for the data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=22'>23</a>\u001b[0m best_attr, best_split \u001b[39m=\u001b[39m find_best_node(new_instances, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=24'>25</a>\u001b[0m sorted_indices \u001b[39m=\u001b[39m instances[\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=25'>26</a>\u001b[0m     :, best_attr\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=26'>27</a>\u001b[0m ]\u001b[39m.\u001b[39margsort()  \u001b[39m# returns sorted instance indices based on the best attribute\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000044?line=27'>28</a>\u001b[0m sorted_instances \u001b[39m=\u001b[39m instances[sorted_indices]  \u001b[39m# sort the instances\u001b[39;00m\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 20'\u001b[0m in \u001b[0;36mfind_best_node\u001b[0;34m(instances, labels)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=18'>19</a>\u001b[0m sorted_labels \u001b[39m=\u001b[39m labels[indices]  \u001b[39m# sort the labels based off the sorted col\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=19'>20</a>\u001b[0m \u001b[39m# Calculate the info gain and optimal split index for a given attribute\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=20'>21</a>\u001b[0m info_gain, split_index \u001b[39m=\u001b[39m get_information_gain( \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=21'>22</a>\u001b[0m     sorted_instances[:, index], sorted_labels\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=22'>23</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m info_gain \u001b[39m>\u001b[39m max_info_gain:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000019?line=24'>25</a>\u001b[0m     max_info_gain \u001b[39m=\u001b[39m info_gain\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 19'\u001b[0m in \u001b[0;36mget_information_gain\u001b[0;34m(instances_col, labels)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_information_gain\u001b[39m(instances_col, labels):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=1'>2</a>\u001b[0m     \u001b[39m\"\"\"Find the information gain for an attribute\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=2'>3</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=3'>4</a>\u001b[0m \u001b[39m    instances_col (numpy.ndarray): Instances Column, numpy array of shape (N, )\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=9'>10</a>\u001b[0m \u001b[39m      best_split_index: The index to to the split point in the column\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=10'>11</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=11'>12</a>\u001b[0m     total_entropy \u001b[39m=\u001b[39m get_entropy(instances_col, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=12'>13</a>\u001b[0m     max_info_gain \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000018?line=13'>14</a>\u001b[0m     split_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;32m/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb Cell 18'\u001b[0m in \u001b[0;36mget_entropy\u001b[0;34m(data, labels)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000017?line=1'>2</a>\u001b[0m H_total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000017?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39munique(labels):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000017?line=3'>4</a>\u001b[0m     probability \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data[labels\u001b[39m==\u001b[39;49mlabel]) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000017?line=4'>5</a>\u001b[0m     H_total \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m probability \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlog2(probability)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williamthomson/Documents/Masters/ML/CW/intro2ml_cw1_12/notebook.ipynb#ch0000017?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m H_total\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "def induce_random_decision_tree(instances, labels, num_attributes_per_tree, depth=0):\n",
    "    \"\"\"Induce a random decision tree for a given dataset\n",
    "\n",
    "    Args:\n",
    "    instances (numpy.ndarray): Instances, numpy array of shape (N, K)\n",
    "                       N is the number of instances\n",
    "                       K is the number of attributes\n",
    "    labels (numpy.ndarray): Class labels, numpy array of shape (N, )\n",
    "                       Each element in labels is a str\n",
    "    num_attributes_per_tree (int): Number of attributes to be used in each tree\n",
    "    Returns:\n",
    "      DecisionNode: A decision node object which contains the attribute, value, left node, right node and depth\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a shuffled array of the indexes of the attributes\n",
    "    random_indexes = default_rng().permutation(len(instances[0, :]))\n",
    "    # Take the first attributes_per_tree indexes\n",
    "    random_indexes_in_each_tree = random_indexes[:num_attributes_per_tree]\n",
    "    # Create a new np array with only the attributes we want\n",
    "    new_instances = instances[:, random_indexes_in_each_tree]\n",
    "\n",
    "    # Find the best split point for the data\n",
    "    best_attr, best_split = find_best_node(new_instances, labels)\n",
    "\n",
    "    sorted_indices = instances[\n",
    "        :, best_attr\n",
    "    ].argsort()  # returns sorted instance indices based on the best attribute\n",
    "    sorted_instances = instances[sorted_indices]  # sort the instances\n",
    "    sorted_labels = labels[sorted_indices]  # sort the labels\n",
    "\n",
    "    # Split the total dataset based on the best split point\n",
    "    (\n",
    "        split_instances_left,\n",
    "        split_instances_right,\n",
    "        split_labels_left,\n",
    "        split_labels_right,\n",
    "    ) = split_dataset(sorted_instances, sorted_labels, best_split)\n",
    "\n",
    "    # If we can no longer split data, return a leaf node\n",
    "    if (\n",
    "        len(set(labels)) == 1\n",
    "        or len(split_instances_left) == 0\n",
    "        or len(split_instances_right) == 0\n",
    "    ):\n",
    "        return Leaf_Node(labels, depth)\n",
    "\n",
    "    # Otherwise return a decision node\n",
    "    LeftNode = induce_decision_tree(\n",
    "        split_instances_left,\n",
    "        split_labels_left,\n",
    "        num_attributes_per_tree,\n",
    "        depth + 1,\n",
    "    )\n",
    "    RightNode = induce_decision_tree(\n",
    "        split_instances_right,\n",
    "        split_labels_right,\n",
    "        num_attributes_per_tree,\n",
    "        depth + 1,\n",
    "    )\n",
    "\n",
    "    # Remap the best attribute its original index\n",
    "    best_attr = random_indexes_in_each_tree[best_attr]\n",
    "\n",
    "    # what to return if left node or right node does not exist\n",
    "    return Decision_Node(\n",
    "        best_attr, sorted_instances[best_split][best_attr], LeftNode, RightNode, depth\n",
    "    )\n",
    "\n",
    "decision_trees = []\n",
    "number_of_trees = 2\n",
    "\n",
    "#Read in data\n",
    "train_instances, train_labels = read_dataset(\"data/train_full.txt\")\n",
    "test_instances, test_labels = read_dataset(\"data/test.txt\")\n",
    "\n",
    "#Get number of attributes in the dataset\n",
    "num_attributes = len(train_instances[0, :])\n",
    "#Take the square root of number of attributes and round up (optimal number of attibutes per tree?)\n",
    "attributes_per_tree = math.ceil(np.sqrt(num_attributes))\n",
    "\n",
    "\n",
    "# Loop through number of trees and train each tree\n",
    "for i in range(0, number_of_trees):\n",
    "    # Create a new random combination of the row indexes from new_instances\n",
    "    random_row_indexes = default_rng().choice(len(x_train), len(x_train))\n",
    "    new_instances = x_train[random_row_indexes, :]\n",
    "    new_labels = x_train[random_row_indexes]\n",
    "\n",
    "    # Now we have the new instances and labels, we can create a new decision tree\n",
    "    new_decision_tree = induce_random_decision_tree(\n",
    "        new_instances, new_labels, attributes_per_tree\n",
    "    )\n",
    "    decision_trees.append(new_decision_tree)\n",
    "\n",
    "    \n",
    "predictions1 = []\n",
    "for i in test_instances:\n",
    "    votes = []\n",
    "    for j in range(len(decision_trees)):\n",
    "        votes.append(decision_trees[j].predict(i))\n",
    "    most_voted_label = max(set(votes), key=votes.count)\n",
    "    predictions1.append(most_voted_label)\n",
    "\n",
    "print(accuracy(test_labels, predictions1))\n",
    "confusion = confusion_matrix(test_labels, np.array(predictions1))\n",
    "print(confusion)\n",
    "(p, macro_p) = precision(test_labels, np.array(predictions1))\n",
    "print(\"precison:\", p)\n",
    "print(\"macro prec:\", macro_p)\n",
    "(r, macro_r) = recall(test_labels, np.array(predictions1))\n",
    "print(\"recall\", r)\n",
    "print(\"macro recall:\", macro_r)\n",
    "(f1, macro_f1) = f1_score(test_labels, np.array(predictions1))\n",
    "print(\"f1:\", f1)\n",
    "print(\"macro f1:\", macro_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915\n"
     ]
    }
   ],
   "source": [
    "#Final evaluation of model with random forests \n",
    "def induce_pruned_decision_tree(instances, labels, max_depth, depth=0):\n",
    "  #Find the best split points for the two \n",
    "  best_attr, best_split = find_best_node(instances, labels)\n",
    "\n",
    "  sorted_indices = instances[:, best_attr].argsort() # returns sorted indices\n",
    "  sorted_instances = instances[sorted_indices] # sort the instances based off sorted col\n",
    "  sorted_labels = labels[sorted_indices] # sort the labels based off the sorted col\n",
    "\n",
    "  #Split the total dataset based on the best split point\n",
    "  split_instances_left, split_instances_right, split_labels_left, split_labels_right = split_dataset(sorted_instances, sorted_labels, best_split)\n",
    "\n",
    "  #If we can no longer split data, return a leaf node\n",
    "  if len(set(labels)) == 1 or len(split_instances_left) == 0 or len(split_instances_right) == 0:\n",
    "    return Leaf_Node(labels, depth)\n",
    "\n",
    "  if depth == max_depth:\n",
    "    return Leaf_Node(labels, depth)\n",
    "\n",
    "  LeftNode = induce_pruned_decision_tree(split_instances_left, split_labels_left, max_depth, depth+1)\n",
    "  RightNode = induce_pruned_decision_tree(split_instances_right, split_labels_right, max_depth,depth+1) \n",
    "\n",
    "  # what to return if left node or right node does not exist\n",
    "  return Decision_Node(best_attr, sorted_instances[best_split][best_attr], LeftNode, RightNode, depth)\n",
    "\n",
    "\n",
    "#Read in data\n",
    "train_instances, train_labels = read_dataset(\"data/train_full.txt\")\n",
    "test_instances, test_labels = read_dataset(\"data/test.txt\")\n",
    "\n",
    "root = induce_pruned_decision_tree(train_instances, train_labels, 15)\n",
    "\n",
    "predictions = []\n",
    "for i in test_instances:\n",
    "  predictions.append(root.predict(i))\n",
    "\n",
    "print(accuracy(test_labels, predictions))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8f9b75f084c32f55a4144a73876ff77ca77854c502638915b4322e4f64aab6d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
